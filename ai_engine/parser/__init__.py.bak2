"""
Contract Parser Module.
Parses contract text and extracts structured sections and clauses.
"""

import re
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum

logger = logging.getLogger(__name__)


class SectionType(Enum):
    """Contract section types."""
    HEADER = "header"
    PARTIES = "parties"
    SUBJECT = "subject"
    RIGHTS = "rights"
    OBLIGATIONS = "obligations"
    PRICE = "price"
    DELIVERY = "delivery"
    QUALITY = "quality"
    WARRANTY = "warranty"
    LIABILITY = "liability"
    FORCE_MAJEURE = "force_majeure"
    DISPUTE = "dispute"
    TERM = "term"
    TERMINATION = "termination"
    CONFIDENTIAL = "confidential"
    ADDITIONAL = "additional"
    REQUISITES = "requisites"
    SIGNATURES = "signatures"
    OTHER = "other"


@dataclass
class Clause:
    """Represents a single clause in a contract."""
    number: str
    content: str
    section_type: SectionType
    start_pos: int
    end_pos: int


@dataclass
class Section:
    """Represents a section of a contract."""
    section_type: SectionType
    title: str
    number: str
    content: str
    clauses: List[Clause] = field(default_factory=list)
    start_pos: int = 0
    end_pos: int = 0


@dataclass
class ContractMetadata:
    """Extracted contract metadata."""
    contract_number: Optional[str] = None
    contract_date: Optional[str] = None
    contract_type: Optional[str] = None
    party_a_name: Optional[str] = None
    party_a_inn: Optional[str] = None
    party_a_address: Optional[str] = None
    party_b_name: Optional[str] = None
    party_b_inn: Optional[str] = None
    party_b_address: Optional[str] = None
    total_amount: Optional[str] = None
    currency: Optional[str] = None
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    language: str = "uz-latn"


class ContractParser:
    """
    Parser for Uzbek contracts.
    Extracts sections, clauses, and metadata from contract text.
    """
    
    # Section header patterns (Uzbek and Russian)
    SECTION_PATTERNS = {
        SectionType.SUBJECT: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:SHARTNOMA\s+PREDMETI|Shartnoma\s+mavzusi)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:PREDMET|MAVZU|SHARTNOMA\s+MAVZUSI)",
            r"(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ПРЕДМЕТ\s+ДОГОВОРА|ШАРТНОМА\s+ПРЕДМЕТИ)",
            r"(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ШАРТНОМА\s+МАВЗУСИ|МАВЗУ)",
            r"(?i)(?:^|\n)\s*(?:Мавзуси)",
        ],
        SectionType.PARTIES: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:TOMONLAR|СТОРОНЫ|Taraflar)",
            r"(?i)bir\s+tomondan.*boshqa\s+tomondan",
            r"(?i)с\s+одной\s+стороны.*с\s+другой\s+стороны",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ТОМОНЛАР|Тарафлар)",
            r"(?i)бир\s+томондан.*иккинчи\s+томондан",
        ],
        SectionType.RIGHTS: [
            r"(?i)(?:^|\n)\s*(?:(?:\d+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:TOMONLARNING\s+HUQUQLARI|ПРАВА\s+СТОРОН|Huquqlar)",
            r"(?i)(?:^|\n)\s*(?:(?:\d+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ҲУҚУҚЛАР|Ҳуқуқлар)",
        ],
        SectionType.OBLIGATIONS: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:TOMONLARNING\s+MAJBURIYATLARI|ОБЯЗАННОСТИ\s+СТОРОН|Majburiyatlar)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:HUQUQ\s+VA\s+MAJBURIYATLAR|ПРАВА\s+И\s+ОБЯЗАННОСТИ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:МАЖБУРИЯТЛАР|Мажбуриятлар|ҲУҚУҚ\s+ВА\s+МАЖБУРИЯТЛАР)",
        ],
        SectionType.PRICE: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:SHARTNOMA\s+NARXI|Shartnoma\s+narxi)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:NARX\s+VA\s+TO['']LOV|QIYMAT|ISHLAR\s+QIYMATI)",
            r"(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ЦЕНА\s+ДОГОВОРА|ЦЕНА\s+И\s+ПОРЯДОК\s+РАСЧЕТОВ|СТОИМОСТЬ)",
            r"(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ПОРЯДОК\s+ОПЛАТЫ)",
            r"(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ШАРТНОМА\s+БЎЙИЧА\s+ИШЛАР\s+ҚИЙМАТИ|ИШЛАР\s+ҚИЙМАТИ|ШАРТНОМА\s+НАРХИ|НАРХ\s+ВА\s+ТЎЛОВ|ТЎЛОВ\s+ТАРТИБИ|ТЎЛОВЛАР\s+ВА\s+ҲИСОБ-КИТОБЛАР|СТОИМОСТЬ\s+РАБОТ)",
        ],
        SectionType.DELIVERY: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:YETKAZIB\s+BERISH|ПОСТАВКА|ДОСТАВКА)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:TOPSHIRISH\s+TARTIBI|ПОРЯДОК\s+СДАЧИ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ЕТКАЗИБ\s+БЕРИШ|ТОПШИРИШ\s+ТАРТИБИ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:СРОКИ\s+И\s+ПОРЯДОК\s+ПОСТАВК\w*)",
        ],
        SectionType.QUALITY: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:SIFAT\s+TALABLARI|ТРЕБОВАНИЯ\s+К\s+КАЧЕСТВУ|Sifat)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:СИФАТ\s+ТАЛАБЛАРИ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:КАЧЕСТВО\s+И\s+КОЛИЧЕСТВО\s+ПРОДУКЦИИ)",
        ],
        SectionType.WARRANTY: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:KAFOLAT|ГАРАНТИЯ|ГАРАНТИЙНЫЕ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:КАФОЛАТ)",
        ],
        SectionType.LIABILITY: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:JAVOBGARLIK|ОТВЕТСТВЕННОСТЬ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:MODDIY\s+JAVOBGARLIK|МАТЕРИАЛЬНАЯ\s+ОТВЕТСТВЕННОСТЬ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ЖАВОБГАРЛИК)",
        ],
        SectionType.FORCE_MAJEURE: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:FORS-MAJOR|ФОРС-МАЖОР|Favqulodda\s+holatlar)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ФОРС-МАЖОР)",
        ],
        SectionType.DISPUTE: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:NIZOLARNI\s+HAL\s+QILISH|РАЗРЕШЕНИЕ\s+СПОРОВ|Nizolar)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:НИЗОЛАРНИ\s+ҲАЛ\s+ҚИЛИШ|НИЗОЛАР)",
        ],
        SectionType.TERM: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:SHARTNOMA\s+MUDDATI|СРОК\s+ДЕЙСТВИЯ|СРОК\s+ДОГОВОРА)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:AMAL\s+QILISH\s+MUDDATI|MUDDATI)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ШАРТНОМА\s+МУДДАТИ|АМАЛ\s+ҚИЛИШ\s+МУДДАТИ|ИШЛАРНИ\s+БАЖАРИШ\s+МУДДАТЛАРИ|СРОКИ\s+ВЫПОЛНЕНИЯ\s+РАБОТ)",
            r"(?i)(?:amal\s+qiladi|действует|срок)",
        ],
        SectionType.TERMINATION: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:SHARTNOMANI\s+BEKOR\s+QILISH|РАСТОРЖЕНИЕ\s+ДОГОВОРА)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ШАРТНОМАНИ\s+БЕКОР\s+ҚИЛИШ)",
        ],
        SectionType.CONFIDENTIAL: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:MAXFIYLIK|КОНФИДЕНЦИАЛЬНОСТЬ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:МАХФИЙЛИК)",
        ],
        SectionType.ADDITIONAL: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:QO['']SHIMCHA\s+SHARTLAR|ДОПОЛНИТЕЛЬНЫЕ\s+УСЛОВИЯ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:BOSHQA\s+SHARTLAR|ПРОЧИЕ\s+УСЛОВИЯ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:YAKUNIY\s+QOIDALAR|ЗАКЛЮЧИТЕЛЬНЫЕ\s+ПОЛОЖЕНИЯ)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ҚЎШИМЧА\s+ШАРТЛАР|БОШҚА\s+ШАРТЛАР|ЯКУНИЙ\s+ҚОИДАЛАР)",
        ],
        SectionType.REQUISITES: [
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:TOMONLARNING\s+REKVIZITLARI|РЕКВИЗИТЫ\s+СТОРОН)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:YURIDIK\s+MANZILLAR|ЮРИДИЧЕСКИЕ\s+АДРЕСА)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:ТОМОНЛАРНИНГ\s+РЕКВИЗИТЛАРИ|ЮРИДИК\s+МАНЗИЛЛАР)",
            r"(?i)(?:^|\n)\s*(?:(?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*)?(?:REKVIZIT|РЕКВИЗИТ)",
        ],
        SectionType.SIGNATURES: [
            r"(?i)(?:^|\n)\s*(?:IMZOLAR|ПОДПИСИ\s+СТОРОН)",
            r"(?i)M\.O['']\..*M\.O['']",  # M.O'. pattern for stamps
            r"(?i)(?:^|\n)\s*(?:ИМЗОЛАР)",
        ],
    }
    
    # Metadata extraction patterns
    METADATA_PATTERNS = {
        'contract_number': [
            # First line header: "ШАРТНОМA No 10 (...)"
            r"(?im)^\s*(?:ШАРТНОМA|ШАРТНОМА|SHARTNOMA|ДОГОВОР|CONTRACT)\s+(?:№|No|N)\.?\s*([\d\-/\А-Я]+)",
            # Generic patterns
            r"(?i)(?:shartnoma|договор|шартнома)\s*(?:raqami|номер|№|No|N|#)\s*([\d\А-Я\-/]+)",
            r"(?i)№\s*([A-Za-z0-9\-/]+)",
            r"(?i)shartnoma\s*№?\s*([A-Za-z0-9\-/]+)",
            r"(?i)договор\s*№?\s*([A-Za-z0-9\-/]+)",
            r"(?i)\b([A-Za-z0-9\-/]+)\b\s*(?:–|-)?\s*сонли",
        ],
        'contract_date': [
            r"(\d{1,2}[\.\-/]\d{1,2}[\.\-/]\d{2,4})",
            r"(\d{1,2})\s+(yanvar|fevral|mart|aprel|may|iyun|iyul|avgust|sentabr|oktabr|noyabr|dekabr|октябр|сентябр|август|июль|июнь|май|апрель|март|февраль|январь|ноябрь|октябрь|декабрь)\s+(\d{4})",
            r"(\d{1,2})\s+(января|февраля|марта|апреля|мая|июня|июля|августа|сентября|октября|ноября|декабря)\s+(\d{4})",
            r"(?i)(?:shartnoma|договор|дата)\s+(?:sanasi|санаси)?\s*[:=]?\s*(\d{1,2}[\.\-/]\d{1,2}[\.\-/]\d{2,4})",
            r"(?i)(?:shartnoma|договор)\s+raqami.*?(\d{1,2}[\.\-/]\d{1,2}[\.\-/]\d{2,4})",
            r"(?i)ш\.\s*\".*?(\d{1,2})\s*(yanvar|fevral|mart|aprel|may|iyun|iyul|avgust|sentabr|oktabr|noyabr|dekabr)\s+(\d{4})",
            r"(\d{1,2})\s+(yanvar|fevral|mart|aprel|may|iyun|iyul|avgust|sentabr|oktabr|noyabr|dekabr)(?:i|da|дагі|дага|дам|дайн)\s+(\d{4})",  # Uzbek suffix forms
        ],
        'inn': [
            r"(?i)(?:INN|ИНН|STIR)[\s:–-]*(\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d)",  # INN label: must have 9 digits
            r"(?i)(?:ШХ|МФО)[\s:]*(\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d)",  # Uzbek STIR format (ШХ)
            r"(\d{9})",  # Standalone 9-digit numbers (as fallback in requisites)
        ],
        'amount': [
            # Cyrillic "қиймати ... 12 476 634 945" (with or without currency)
            r"(?i)(?:шартноманинг|шартнома\s+буйича\s+(?:ишлар\s+)?|ишлар\s+)?(?:умумий\s+)?(?:қиймати|киймати|нарх[и]?)\s*(?:таҳминий\s+)?(?:ққс\s+билан\s+)?([\d\s]{10,})",
            r"(?i)(?:шартнома\s+буйича\s+(?:ишлар\s+)?киймати|киймати|нарх[и]?)\s*(?:барча\s+соликлар[,\s]*)?[\s]*(\d[\d\s]+)\s*(?:сум|сўм|UZS|USD|EUR|RUB)",
            r"(?i)(?:шартнома\s+буйича\s+ишлар|ишлар\s+қиймати|қиймати|нарх[и]?)\s*[\s]*(\d[\d\s]+)\s*(?:сумни|сум|сўм|UZS|USD|EUR|RUB)",
            r"(?i)(\d{1,3}[\s]+\d{3}[\s]+\d{3}[\s]+\d{3})\s*(?:сумни|сумлик|\(|сум|сўм)",
            r"(?i)(\d{1,3}[\s]*(?:\d{3}[\s]*)*(?:\d{1,3})?)\s*(?:so['']m|so[''`]?m|сум|сўм|UZS|USD|EUR|RUB|₽|\$)",
            r"(?i)jami\s*[:=]?\s*(\d[\d\s]*[\.,]?\d*)",
            r"(?i)итого\s*[:=]?\s*(\d[\d\s]*[\.,]?\d*)",
            r"(?i)(\d[\d\s]*[\.,]?\d*)\s*(?:uzs|usd|eur|rub)",
            r"(?i)(?:shartnoma\s+summasi|shartnoma\s+narxi|shartnoma\s+bo'yicha\s+ishlar\s+qiymati|jami)\s*[:=]?\s*(\d[\d\s]*[\.,]?\d*)",
        ],
    }
    PARTY_PATTERNS = {
        'party_a_name': [
            # Search in requisites section: Заказчик, then next Наименование line - from END of document backwards
            r"(?ims)(?:Заказчик|Покупатель).*?Наименование[:\s]+([^\n]+?)(?=\s*(?:Телефон|Факс|ИНН|ОКЭД|Адрес|$))",
            # Intro clause definitions: "Буюртмачи" деб юритиладиган "<name>"
            r"(?is)(?:кейинги|keyingi)\s+(?:уринларда|ўринларда|o['’`]?rinlarda)\s*[\"“”']?\s*буюртмачи\s*[\"“”']?\s+деб\s+юритилад(?:и|иг)ган\s*[\"“”']?([^\"”]{3,200})",
            # Line-anchored labels to avoid mid-sentence matches
            r"(?im)(?:^|\n)\s*(?:Заказчик|Покупатель)\s*[:–—-]+\s*([^\n]+)",
            r"(?im)(?:^|\n)\s*(?:1[-\s]*tomon|birinchi\s+tomon|buyurtmachi|zakazchik|заказчик|Буюртмачи)\s*[:–—-]+\s*([^\n]+)",
        ],
        'party_b_name': [
            # Search in requisites section: Исполнитель, then next Наименование line - from END of document backwards
            r"(?ims)(?:Исполнитель|Поставщик).*?Наименование[:\s]+([^\n]+?)(?=\s*(?:Телефон|Факс|ИНН|ОКЭД|Адрес|$))",
            # Intro clause definitions: "Пудратчи/Ижрочи" деб юритиладиган "<name>"
            r"(?is)(?:кейинги|keyingi)\s+(?:уринларда|ўринларда|o['’`]?rinlarda)\s*[\"“”']?\s*(?:пудратчи|ижрочи|pudratchi|ijrochi)\s*[\"“”']?\s+деб\s+юритилад(?:и|иг)ган\s*[\"“”']?([^\"”]{3,200})",
            # Line-anchored labels to avoid mid-sentence matches
            r"(?im)(?:^|\n)\s*(?:Исполнитель|Поставщик|Подрядчик)\s*[:–—-]+\s*([^\n]+)",
            r"(?im)(?:^|\n)\s*(?:2[-\s]*tomon|ikkinchi\s+tomon|ijrochi|pudratchi|podryadchik|исполнитель|Пудратчи)\s*[:–—-]+\s*([^\n]+)",
        ],
    }
    
    def __init__(self):
        """Initialize the parser."""
        self.compiled_patterns = {}
        self._compile_patterns()
    
    def _compile_patterns(self):
        """Compile regex patterns for better performance."""
        for section_type, patterns in self.SECTION_PATTERNS.items():
            self.compiled_patterns[section_type] = [
                re.compile(p, re.MULTILINE | re.UNICODE)
                for p in patterns
            ]
    
    def parse(self, text: str) -> Tuple[List[Section], ContractMetadata]:
        """
        Parse contract text and extract sections and metadata.
        
        Args:
            text: Contract text
            
        Returns:
            Tuple of (sections list, metadata)
        """
        # Normalize text to improve section/metadata detection
        text = self._normalize_text(text)
        # Extract metadata
        metadata = self._extract_metadata(text)
        
        # Find section boundaries
        section_positions = self._find_section_positions(text)
        
        # Extract sections
        sections = self._extract_sections(text, section_positions)
        
        # Extract clauses within each section
        for section in sections:
            section.clauses = self._extract_clauses(section.content, section.section_type)
        
        return sections, metadata

    def _normalize_text(self, text: str) -> str:
        """Normalize common OCR artifacts (hyphenation, apostrophes, spaces, EOLs)."""
        if not text:
            return text
        # Harmonize mixed Latin/Cyrillic lookalike letters in Cyrillic-dominant texts
        try:
            total_letters = sum(1 for c in text if c.isalpha())
            cyr_letters = sum(1 for c in text if 'А' <= c <= 'я' or c in 'ЁёЎўҒғҚқҲҳ')
            cyr_ratio = (cyr_letters / total_letters) if total_letters else 0
            if cyr_ratio >= 0.6:
                # Map Latin lookalikes to Cyrillic to fix headers like "ШАРТНОМA" → "ШАРТНОМА"
                latin_to_cyr = {
                    'A': 'А', 'a': 'а',
                    'B': 'В', 'b': 'в',
                    'E': 'Е', 'e': 'е',
                    'K': 'К', 'k': 'к',
                    'M': 'М', 'm': 'м',
                    'H': 'Н', 'h': 'н',
                    'O': 'О', 'o': 'о',
                    'P': 'Р', 'p': 'р',
                    'C': 'С', 'c': 'с',
                    'T': 'Т', 't': 'т',
                    'X': 'Х', 'x': 'х',
                    'Y': 'У', 'y': 'у',  # careful but helps for full-uppercase headings
                }
                text = ''.join(latin_to_cyr.get(ch, ch) for ch in text)
        except Exception:
            # If anything goes wrong, keep original text
            pass
        # Join hyphenation broken at EOL: word-\nword -> wordword
        text = re.sub(r"(\w)-\n(\w)", r"\1\2", text)
        # Normalize apostrophes/backticks/quotes to a single apostrophe
        text = text.replace("`", "'")
        text = text.replace("’", "'").replace("ʻ", "'").replace("ʼ", "'").replace("‘", "'")
        # Collapse multiple spaces
        text = re.sub(r"[ \t]{2,}", " ", text)
        # Normalize line endings
        text = text.replace("\r\n", "\n").replace("\r", "\n")
        # Insert newlines before numbered headings that often get concatenated in OCR
        # e.g., "... Сторона, заключили ... 1. ПРЕДМЕТ ДОГОВОРА" -> place newline before "1."
        # Also support Roman numerals and Cyrillic letters as section prefixes (П., Ш., I., II., etc.)
        text = re.sub(r"(?<!\n)(\s)((?:[\dIVX]+|[A-ZА-ЯЁЎҚҲҒ]{1,3})[\.\)]\s*[A-ZА-ЯЁЎҚҲҒ])", r"\1\n\2", text)
        # Insert newlines before common Russian/Uzbek section headers if missing line breaks
        header_keywords = [
            r"ПРЕДМЕТ ДОГОВОРА", r"ЦЕНА ДОГОВОРА", r"ПОРЯДОК РАСЧЕТОВ", r"СРОК ДЕЙСТВИЯ",
            r"ОТВЕТСТВЕННОСТЬ", r"ЮРИДИЧЕСКИЕ АДРЕСА", r"РЕКВИЗИТЫ СТОРОН",
            r"ШАРТНОМА МАВЗУСИ", r"ШАРТНОМА БЎЙИЧА ИШЛАР ҚИЙМАТИ", r"ИШЛАРНИ БAЖАРИШ МУДДАТЛАРИ",
            r"Шартнома предмети", r"Narx", r"Muddat", r"Javobgarlik", r"Rekvizitlari"
        ]
        for kw in header_keywords:
            text = re.sub(rf"(?<!\n)\s({kw})", r"\n\1", text, flags=re.IGNORECASE)
        return text
    
    def _extract_metadata(self, text: str) -> ContractMetadata:
        """Extract metadata from contract text."""
        metadata = ContractMetadata()
        
        # Extract contract number
        for pattern in self.METADATA_PATTERNS['contract_number']:
            match = re.search(pattern, text)
            if match:
                metadata.contract_number = match.group(1)
                break
        
        # Extract contract date
        for pattern in self.METADATA_PATTERNS['contract_date']:
            match = re.search(pattern, text)
            if match:
                metadata.contract_date = match.group(0)
                break
        
        # Extract INNs - try multiple patterns
        import logging
        logger_local = logging.getLogger(__name__)
        
        # First, try to extract from requisites section only (most reliable)
        requisites_anchors = [
            r"ЮРИДИЧЕСКИЕ\s+АДРЕСА",
            r"РЕКВИЗИТЫ\s+СТОРОН",
            r"ТОМОНЛАРНИНГ\s+РЕКВИЗИТЛАРИ",
            r"TOMONLARNING\s+REKVIZITLARI",
            r"ЮРИДИК\s+МАНЗИЛЛАР",
            r"REKVIZIT",
        ]
        requisites_text = ""
        for anchor in requisites_anchors:
            for m in re.finditer(anchor, text, flags=re.IGNORECASE):
                # Get 2000 chars after anchor
                requisites_text = text[m.start():m.start()+2000]
                break
            if requisites_text:
                break
        
        # Extract INNs from requisites first
        all_inns = []
        if requisites_text:
            # Try INN label pattern first in requisites
            inn_from_label = re.findall(r"(?i)(?:INN|ИНН)\s*(\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d[\s–-]*\d)", requisites_text)
            if inn_from_label:
                all_inns.extend(inn_from_label)
                logger_local.info(f"[INN_EXTRACT] From requisites INN labels: {inn_from_label}")
        
        # If not enough from requisites, try full text
        if len(all_inns) < 2:
            for pattern in self.METADATA_PATTERNS['inn']:
                inns = re.findall(pattern, text)
                logger_local.info(f"[INN_EXTRACT] Pattern '{pattern[:50]}...': found {len(inns)} matches")
                if inns:
                    all_inns.extend(inns)
        
        # Normalize INNs (remove spaces/dashes from within)
        normalized_inns = []
        for inn in all_inns:
            normalized_inn = re.sub(r'[\s–-]', '', inn)  # Remove spaces and dashes
            if len(normalized_inn) == 9 and normalized_inn.isdigit():  # Valid 9-digit INN
                normalized_inns.append(normalized_inn)
                logger_local.info(f"[INN_EXTRACT] Valid INN: {inn} -> {normalized_inn}")
        
        # Remove duplicates while preserving order
        seen = set()
        unique_inns = []
        for inn in normalized_inns:
            if inn not in seen:
                seen.add(inn)
                unique_inns.append(inn)
        
        # Take only the first two (if more, discard extras likely from OCR corruption)
        unique_inns = unique_inns[:2]
        
        logger_local.info(f"[INN_EXTRACT] Final unique INNs: {unique_inns}")
        if len(unique_inns) >= 1:
            metadata.party_a_inn = unique_inns[0]
        if len(unique_inns) >= 2:
            metadata.party_b_inn = unique_inns[1]
        
        # Extract amount
        for pattern in self.METADATA_PATTERNS['amount']:
            match = re.search(pattern, text)
            if match:
                amount_raw = match.group(1).strip()
                logger_local.info(f"[AMOUNT_EXTRACT] Pattern matched: '{pattern[:80]}...', raw: '{amount_raw[:80]}'")
                # Skip very small numbers (< 100,000) using robust numeric parsing
                amount_clean = re.sub(r'[\s–-]', '', amount_raw)
                skip_small = False
                try:
                    amount_val_float = float(amount_clean.replace(',', '.'))
                    if amount_val_float < 100000:
                        skip_small = True
                except Exception:
                    # Fallback: digits-only compare
                    digits_only = re.sub(r'[^0-9]', '', amount_raw)
                    if digits_only and digits_only.isdigit():
                        try:
                            if int(digits_only) < 100000:
                                skip_small = True
                        except Exception:
                            pass
                if skip_small:
                    logger_local.info(f"[AMOUNT_EXTRACT] Skipping small number: {amount_clean}")
                    continue

                # Store a normalized numeric string representing whole currency units
                normalized_numeric: str
                try:
                    # Prefer robust float parsing, then round to whole units
                    parsed = float(amount_clean.replace(',', '.'))
                    normalized_numeric = str(int(round(parsed)))
                except Exception:
                    # Fallback: digits-only, but avoid inflating values with decimals
                    # If raw contains a decimal part, drop it instead of concatenating
                    if '.' in amount_clean or ',' in amount_clean:
                        digits_before = re.sub(r'[^0-9].*$', '', amount_clean)
                        normalized_numeric = re.sub(r'[^0-9]', '', digits_before)
                    else:
                        normalized_numeric = re.sub(r'[^0-9]', '', amount_raw)

                logger_local.info(f"[AMOUNT_EXTRACT] Found: '{amount_raw[:50]}...' -> '{normalized_numeric}'")
                metadata.total_amount = normalized_numeric
                break
        
        # Fallback: if no amount found, search more aggressively in requisites
        if not metadata.total_amount:
            # Try specific section header: "ШАРТНОМА БУЙИЧА ИШЛАР КИЙМАТИ" or "Ш. ШАРТНОМА"
            section_match = re.search(r"(?i)(?:ш\.|шартнома буйича ишлар киймати).*?(?:сумни|сумлик)\s+(\d[\d\s]+?)\s*(?:\(|сум)", text, re.DOTALL)
            if section_match:
                amount_val = re.sub(r'[\s–-]', '', section_match.group(1).strip())
                if len(amount_val) >= 10:  # Reasonable contract amount
                    logger_local.info(f"[AMOUNT_EXTRACT] Section found: '{section_match.group(1).strip()}' -> '{amount_val}'")
                    metadata.total_amount = amount_val
        
        # If still no valid amount or too small, try one more search
        try:
            if not metadata.total_amount or (metadata.total_amount and float(metadata.total_amount) < 100000):
                # Search for 270 460 577 128 pattern anywhere
                large_amount = re.search(r'(\d{3,4}[\s]+\d{3}[\s]+\d{3}[\s]+\d{3})', text)
                if large_amount:
                    amount_val = re.sub(r'[\s–-]', '', large_amount.group(1))
                    logger_local.info(f"[AMOUNT_EXTRACT] Large amount pattern found: {amount_val}")
                    metadata.total_amount = amount_val
        except (ValueError, TypeError):
            pass
        
        # Detect currency
        if 'USD' in text.upper() or '$' in text:
            metadata.currency = 'USD'
        elif 'EUR' in text.upper() or '€' in text:
            metadata.currency = 'EUR'
        else:
            metadata.currency = 'UZS'
        
        # Detect language
        metadata.language = self._detect_language(text)
        
        metadata.party_a_name = self._extract_party(text, 'party_a_name')
        metadata.party_b_name = self._extract_party(text, 'party_b_name')

        return metadata

    def _extract_party(self, text: str, field: str) -> Optional[str]:
        """Extract party name using defined patterns."""
        import logging
        logger = logging.getLogger(__name__)
        
        # First, try to find the requisites section (typically at end with "9. Юридические адреса")
        requisites_anchors = [
            r"ЮРИДИЧЕСКИЕ\s+АДРЕСА",
            r"РЕКВИЗИТЫ\s+СТОРОН",
            r"ТОМОНЛАРНИНГ\s+РЕКВИЗИТЛАРИ",
            r"TOMONLARNING\s+REKVIZITLARI",
            r"ЮРИДИК\s+МАНЗИЛЛАР",
            r"REKVIZIT",
        ]
        anchor_match = None
        for anchor in requisites_anchors:
            for m in re.finditer(anchor, text, flags=re.IGNORECASE):
                anchor_match = m

        search_blocks = []
        if anchor_match:
            search_blocks.append(text[anchor_match.start():])
            logger.info(f"[PARTY_EXTRACT] Found requisites anchor '{anchor_match.group(0)}', searching within it")
        else:
            logger.info(f"[PARTY_EXTRACT] No requisites section found, searching last 50k chars")

        search_blocks.append(text[-50000:])

        for search_text in search_blocks:
            for pattern in self.PARTY_PATTERNS.get(field, []):
                match = re.search(pattern, search_text)
                if match:
                    value = match.group(1).strip()
                    logger.info(f"[PARTY_EXTRACT] {field} matched pattern, raw value: {value[:100]}")
                    
                    # Stop at common delimiters that usually introduce requisites or amounts
                    value = re.split(r"\b(?:ИНН|INN|STIR|Адрес|Address|Телефон|Факс|ОКЭД|Банк|Р/С|р/с|МФО)\b", value)[0].strip()
                    logger.info(f"[PARTY_EXTRACT] {field} after split: {value[:100]}")
                    
                    # Keep a reasonable length to avoid swallowing large tables
                    if len(value) > 200:
                        value = value[:200].rstrip()
                        logger.info(f"[PARTY_EXTRACT] {field} truncated to 200 chars")
                        
                    return value
        logger.info(f"[PARTY_EXTRACT] {field} - NO MATCH")
        return None
    
    def _detect_language(self, text: str) -> str:
        """Detect contract language: Russian, Uzbek Cyrillic, or Latin."""
        import logging
        logger = logging.getLogger(__name__)
        
        cyrillic = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ')
        russian_specific = set('ъыэё')
        uzbek_specific = set("ғҳқўшчђҷ")
        
        cyrillic_count = sum(1 for c in text if c in cyrillic)
        russian_count = sum(1 for c in text if c in russian_specific)
        uzbek_indicator = sum(1 for c in text if c in uzbek_specific)
        total_letters = sum(1 for c in text if c.isalpha())
        
        if total_letters == 0:
            return 'uz-latn'
        
        cyrillic_ratio = cyrillic_count / total_letters
        
        logger.info(f"[LANG_DETECT] cyrillic_count={cyrillic_count}, russian_count={russian_count}, uzbek_indicator={uzbek_indicator}, total_letters={total_letters}, cyrillic_ratio={cyrillic_ratio:.2%}")
        
        if cyrillic_ratio > 0.5:
            # If Uzbek-specific letters dominate, prefer Uzbek Cyrillic even when Russian letters exist
            if uzbek_indicator >= 5 and uzbek_indicator >= max(1, russian_count // 2):
                logger.info(f"[LANG_DETECT] RETURNING: uz-cyrl (uzbek chars dominate: uzbek_indicator={uzbek_indicator}, russian_count={russian_count})")
                return 'uz-cyrl'

            # Check for Russian-specific words
            russian_words = ['договор', 'поставщик', 'исполнитель', 'заказчик', 'покупатель', 'условиях', 'расчетов']
            russian_word_count = sum(1 for word in russian_words if word in text.lower())
            
            logger.info(f"[LANG_DETECT] russian_word_count={russian_word_count}, words found: {[w for w in russian_words if w in text.lower()]}")
            
            # If Russian-specific characters detected, it's Russian
            if russian_count >= 5:
                logger.info(f"[LANG_DETECT] RETURNING: ru (has russian_specific chars: russian_count={russian_count})")
                return 'ru'
            
            # If Russian-specific words detected (high confidence), it's Russian
            if russian_word_count >= 5:
                logger.info(f"[LANG_DETECT] RETURNING: ru (has many russian_words: russian_word_count={russian_word_count})")
                return 'ru'
            
            # If some Russian words and no Uzbek characters, it's Russian
            if russian_word_count >= 2 and uzbek_indicator == 0:
                logger.info(f"[LANG_DETECT] RETURNING: ru (russian_words + no uzbek chars)")
                return 'ru'
            
            # If Uzbek-specific letters present, prefer Uzbek Cyrillic (mixed contracts)
            if uzbek_indicator >= 1:
                logger.info(f"[LANG_DETECT] RETURNING: uz-cyrl (uzbek_indicator={uzbek_indicator})")
                return 'uz-cyrl'
            
            # Default to Uzbek Cyrillic for ambiguous Cyrillic text
            logger.info(f"[LANG_DETECT] RETURNING: uz-cyrl (default for ambiguous)")
            return 'uz-cyrl'
        
        logger.info(f"[LANG_DETECT] RETURNING: uz-latn (cyrillic_ratio too low)")
        return 'uz-latn'
    
    def _find_section_positions(self, text: str) -> List[Tuple[int, int, SectionType, str]]:
        """Find positions of all sections in text."""
        positions = []
        
        for section_type, patterns in self.compiled_patterns.items():
            for pattern in patterns:
                for match in pattern.finditer(text):
                    positions.append((
                        match.start(),
                        match.end(),
                        section_type,
                        match.group(0).strip()
                    ))
        
        # Sort by position
        positions.sort(key=lambda x: x[0])
        
        # Remove duplicates (same position, keep first)
        unique_positions = []
        last_pos = -100
        for pos in positions:
            if pos[0] - last_pos > 50:  # At least 50 chars apart
                unique_positions.append(pos)
                last_pos = pos[0]
        
        return unique_positions
    
    def _extract_sections(self, text: str, positions: List[Tuple[int, int, SectionType, str]]) -> List[Section]:
        """Extract sections based on found positions."""
        sections = []
        
        # Add header section (text before first section)
        if positions and positions[0][0] > 0:
            header_text = text[:positions[0][0]].strip()
            if header_text:
                sections.append(Section(
                    section_type=SectionType.HEADER,
                    title="Sarlavha",
                    number="",
                    content=header_text,
                    start_pos=0,
                    end_pos=positions[0][0]
                ))
        
        # Extract each section
        for i, (start, header_end, section_type, title) in enumerate(positions):
            # Determine end position
            if i + 1 < len(positions):
                end = positions[i + 1][0]
            else:
                end = len(text)
            
            content = text[header_end:end].strip()
            
            # Extract section number from title
            number_match = re.match(r'^(\d+)[\.\)]', title)
            number = number_match.group(1) if number_match else ""
            
            sections.append(Section(
                section_type=section_type,
                title=title,
                number=number,
                content=content,
                start_pos=start,
                end_pos=end
            ))
        
        return sections
    
    def _extract_clauses(self, content: str, section_type: SectionType) -> List[Clause]:
        """Extract individual clauses from section content."""
        clauses = []
        
        # Pattern for numbered clauses like "1.1", "2.3.1", etc.
        clause_pattern = re.compile(
            r'(?:^|\n)\s*(\d+(?:\.\d+)*)[\.:\)]\s*(.+?)(?=(?:\n\s*\d+(?:\.\d+)*[\.:\)])|$)',
            re.DOTALL
        )
        
        for match in clause_pattern.finditer(content):
            clause_number = match.group(1)
            clause_content = match.group(2).strip()
            
            if clause_content:
                clauses.append(Clause(
                    number=clause_number,
                    content=clause_content,
                    section_type=section_type,
                    start_pos=match.start(),
                    end_pos=match.end()
                ))
        
        return clauses
    
    def get_section_by_type(self, sections: List[Section], section_type: SectionType) -> Optional[Section]:
        """Get section by type."""
        for section in sections:
            if section.section_type == section_type:
                return section
        return None
    
    def get_missing_sections(self, sections: List[Section], required_types: List[SectionType]) -> List[SectionType]:
        """Find missing required sections."""
        found_types = {s.section_type for s in sections}
        return [t for t in required_types if t not in found_types]
